{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification \n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.models import EModel, Wav2Vec2Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/joono/anaconda3/envs/torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/work/joono/anaconda3/envs/torch/lib/python3.12/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Trainable Lora layers ===========\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([768, 8])\n",
      "torch.Size([256, 768])\n",
      "torch.Size([256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2])\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"facebook/wav2vec2-base\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "\n",
    "path = \"/home/work/joono/joono/joono/DV_DV.Deep/te7xe6lt/checkpoints/best-checkpoint_oneshot.ckpt\"\n",
    "model = Wav2Vec2Facebook.load_from_checkpoint(path, args={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path):\n",
    "    audio, _ = librosa.load(path, sr=sampling_rate)\n",
    "    inputs = feature_extractor(audio, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    return inputs.input_values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate 함수 정의\n",
    "def collate_fn(batch):\n",
    "    signals, labels = zip(*batch)\n",
    "    max_length = max([signal.size(0) for signal in signals])\n",
    "    padded_signals = torch.zeros(len(signals), max_length)\n",
    "    for i, signal in enumerate(signals):\n",
    "        padded_signals[i, :signal.size(0)] = signal\n",
    "    labels = torch.tensor(labels)\n",
    "    return padded_signals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(\"..\", \"dataset\", self.df.loc[idx, 'path'])\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {path}\")     \n",
    "        signal = speech_file_to_array_fn(path)           \n",
    "        return signal, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../dataset/test.csv', index_col=None)\n",
    "test_df['path'] = '../dataset/' + test_df['path'].str[1:]\n",
    "test_dataset = TestDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, num_workers=24, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probs = model(inputs)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:19<00:00, 19.63it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model=model, test_loader=test_loader, device='cuda:0')\n",
    "# preds = model.inference(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3325986/1721487462.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.11636830866336823' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  else                            : submit.iloc[i, 1] = preds[i][0]\n",
      "/tmp/ipykernel_3325986/1721487462.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9687573909759521' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  else                            : submit.iloc[i, 2] = preds[i][1]\n",
      "100%|██████████| 50000/50000 [00:08<00:00, 6148.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>TEST_01000</td>\n",
       "      <td>0.210188</td>\n",
       "      <td>0.901941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>TEST_01001</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.995438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>TEST_01002</td>\n",
       "      <td>0.066197</td>\n",
       "      <td>0.978072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>TEST_01003</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.364453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>TEST_01004</td>\n",
       "      <td>0.366598</td>\n",
       "      <td>0.921620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>TEST_01005</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>0.876438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>TEST_01006</td>\n",
       "      <td>0.043989</td>\n",
       "      <td>0.938361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>TEST_01007</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.917152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>TEST_01008</td>\n",
       "      <td>0.128964</td>\n",
       "      <td>0.991209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>TEST_01009</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>0.925891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>TEST_01010</td>\n",
       "      <td>0.634734</td>\n",
       "      <td>0.923838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>TEST_01011</td>\n",
       "      <td>0.909711</td>\n",
       "      <td>0.248122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>TEST_01012</td>\n",
       "      <td>0.304989</td>\n",
       "      <td>0.970393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>TEST_01013</td>\n",
       "      <td>0.114561</td>\n",
       "      <td>0.990699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>TEST_01014</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.932193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>TEST_01015</td>\n",
       "      <td>0.017247</td>\n",
       "      <td>0.994842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>TEST_01016</td>\n",
       "      <td>0.070750</td>\n",
       "      <td>0.976868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>TEST_01017</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.889018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>TEST_01018</td>\n",
       "      <td>0.307198</td>\n",
       "      <td>0.911510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>TEST_01019</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>0.818753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>TEST_01020</td>\n",
       "      <td>0.696038</td>\n",
       "      <td>0.942393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>TEST_01021</td>\n",
       "      <td>0.052867</td>\n",
       "      <td>0.994076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>TEST_01022</td>\n",
       "      <td>0.341184</td>\n",
       "      <td>0.513666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>TEST_01023</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.869017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>TEST_01024</td>\n",
       "      <td>0.177990</td>\n",
       "      <td>0.941087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>TEST_01025</td>\n",
       "      <td>0.722368</td>\n",
       "      <td>0.927743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>TEST_01026</td>\n",
       "      <td>0.596525</td>\n",
       "      <td>0.875016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>TEST_01027</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.784941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>TEST_01028</td>\n",
       "      <td>0.025291</td>\n",
       "      <td>0.984818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>TEST_01029</td>\n",
       "      <td>0.046971</td>\n",
       "      <td>0.982811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>TEST_01030</td>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.828844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>TEST_01031</td>\n",
       "      <td>0.997781</td>\n",
       "      <td>0.005886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>TEST_01032</td>\n",
       "      <td>0.078995</td>\n",
       "      <td>0.988478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>TEST_01033</td>\n",
       "      <td>0.117693</td>\n",
       "      <td>0.988286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>TEST_01034</td>\n",
       "      <td>0.173812</td>\n",
       "      <td>0.872270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>TEST_01035</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.956295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>TEST_01036</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.282943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>TEST_01037</td>\n",
       "      <td>0.130855</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>TEST_01038</td>\n",
       "      <td>0.047713</td>\n",
       "      <td>0.980761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>TEST_01039</td>\n",
       "      <td>0.747283</td>\n",
       "      <td>0.574981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>TEST_01040</td>\n",
       "      <td>0.562329</td>\n",
       "      <td>0.825623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>TEST_01041</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.752864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>TEST_01042</td>\n",
       "      <td>0.306111</td>\n",
       "      <td>0.973069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>TEST_01043</td>\n",
       "      <td>0.269430</td>\n",
       "      <td>0.830293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>TEST_01044</td>\n",
       "      <td>0.094257</td>\n",
       "      <td>0.990846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>TEST_01045</td>\n",
       "      <td>0.025072</td>\n",
       "      <td>0.993879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>TEST_01046</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.757783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>TEST_01047</td>\n",
       "      <td>0.027664</td>\n",
       "      <td>0.987394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>TEST_01048</td>\n",
       "      <td>0.489039</td>\n",
       "      <td>0.710258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>TEST_01049</td>\n",
       "      <td>0.016567</td>\n",
       "      <td>0.996054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id      fake      real\n",
       "1000  TEST_01000  0.210188  0.901941\n",
       "1001  TEST_01001  0.068295  0.995438\n",
       "1002  TEST_01002  0.066197  0.978072\n",
       "1003  TEST_01003  0.070671  0.364453\n",
       "1004  TEST_01004  0.366598  0.921620\n",
       "1005  TEST_01005  0.031512  0.876438\n",
       "1006  TEST_01006  0.043989  0.938361\n",
       "1007  TEST_01007  0.280403  0.917152\n",
       "1008  TEST_01008  0.128964  0.991209\n",
       "1009  TEST_01009  0.018735  0.925891\n",
       "1010  TEST_01010  0.634734  0.923838\n",
       "1011  TEST_01011  0.909711  0.248122\n",
       "1012  TEST_01012  0.304989  0.970393\n",
       "1013  TEST_01013  0.114561  0.990699\n",
       "1014  TEST_01014  0.014629  0.932193\n",
       "1015  TEST_01015  0.017247  0.994842\n",
       "1016  TEST_01016  0.070750  0.976868\n",
       "1017  TEST_01017  0.027042  0.889018\n",
       "1018  TEST_01018  0.307198  0.911510\n",
       "1019  TEST_01019  0.066132  0.818753\n",
       "1020  TEST_01020  0.696038  0.942393\n",
       "1021  TEST_01021  0.052867  0.994076\n",
       "1022  TEST_01022  0.341184  0.513666\n",
       "1023  TEST_01023  0.007056  0.869017\n",
       "1024  TEST_01024  0.177990  0.941087\n",
       "1025  TEST_01025  0.722368  0.927743\n",
       "1026  TEST_01026  0.596525  0.875016\n",
       "1027  TEST_01027  0.012713  0.784941\n",
       "1028  TEST_01028  0.025291  0.984818\n",
       "1029  TEST_01029  0.046971  0.982811\n",
       "1030  TEST_01030  0.021947  0.828844\n",
       "1031  TEST_01031  0.997781  0.005886\n",
       "1032  TEST_01032  0.078995  0.988478\n",
       "1033  TEST_01033  0.117693  0.988286\n",
       "1034  TEST_01034  0.173812  0.872270\n",
       "1035  TEST_01035  0.005349  0.956295\n",
       "1036  TEST_01036  0.591173  0.282943\n",
       "1037  TEST_01037  0.130855  0.987500\n",
       "1038  TEST_01038  0.047713  0.980761\n",
       "1039  TEST_01039  0.747283  0.574981\n",
       "1040  TEST_01040  0.562329  0.825623\n",
       "1041  TEST_01041  0.012130  0.752864\n",
       "1042  TEST_01042  0.306111  0.973069\n",
       "1043  TEST_01043  0.269430  0.830293\n",
       "1044  TEST_01044  0.094257  0.990846\n",
       "1045  TEST_01045  0.025072  0.993879\n",
       "1046  TEST_01046  0.007067  0.757783\n",
       "1047  TEST_01047  0.027664  0.987394\n",
       "1048  TEST_01048  0.489039  0.710258\n",
       "1049  TEST_01049  0.016567  0.996054"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('/home/work/joono/joono/dataset/sample_submission.csv')\n",
    "\n",
    "max_thres = 0.999\n",
    "min_thres = 0.001\n",
    "\n",
    "for i in tqdm(range(len(preds))):\n",
    "    if      preds[i][0] > max_thres : submit.iloc[i, 1] = 1\n",
    "    elif    preds[i][0] < min_thres : submit.iloc[i, 1] = 0 \n",
    "    else                            : submit.iloc[i, 1] = preds[i][0]\n",
    "    if      preds[i][1] > max_thres : submit.iloc[i, 2] = 1\n",
    "    elif    preds[i][1] < min_thres : submit.iloc[i, 2] = 0 \n",
    "    else                            : submit.iloc[i, 2] = preds[i][1]\n",
    "\n",
    "submit[1000:1050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('joono_wav2vec2_lora_train_test_align_test_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
