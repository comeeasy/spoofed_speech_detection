{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import HubertForSequenceClassification, AutoConfig, Wav2Vec2FeatureExtractor\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import EModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/joono/anaconda3/envs/torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = 'facebook/hubert-large-ll60k'\n",
    "config = AutoConfig.from_pretrained(model_name_or_path, num_labels=2)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at facebook/hubert-large-ll60k and are newly initialized: ['classifier.bias', 'classifier.weight', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = EModel(config=config)\n",
    "model = EModel.load_from_checkpoint(\"/home/work/joono/joono/joono/DV_DV.Deep/czvypyil/checkpoints/best-checkpoint.ckpt\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path):\n",
    "    audio, _ = librosa.load(path, sr=sampling_rate)\n",
    "    inputs = feature_extractor(audio, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    return inputs.input_values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate 함수 정의\n",
    "def collate_fn(batch):\n",
    "    signals, labels = zip(*batch)\n",
    "    max_length = max([signal.size(0) for signal in signals])\n",
    "    padded_signals = torch.zeros(len(signals), max_length)\n",
    "    for i, signal in enumerate(signals):\n",
    "        padded_signals[i, :signal.size(0)] = signal\n",
    "    labels = torch.tensor(labels)\n",
    "    return padded_signals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(\"..\", \"dataset\", self.df.loc[idx, 'path'])\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {path}\")     \n",
    "        signal = speech_file_to_array_fn(path)           \n",
    "        return signal, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../dataset/test.csv', index_col=None)\n",
    "test_df['path'] = '../dataset/' + test_df['path'].str[1:]\n",
    "test_dataset = TestDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, num_workers=24, batch_size=8, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probs = model(inputs)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6250 [00:00<?, ?it/s]/home/work/joono/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "100%|██████████| 6250/6250 [03:38<00:00, 28.54it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model=model, test_loader=test_loader,device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/tmp/ipykernel_3262718/1368565751.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4800666570663452' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  else                            : submit.iloc[i, 1] = preds[i][0]\n",
      "/tmp/ipykernel_3262718/1368565751.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5238075256347656' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  else                            : submit.iloc[i, 2] = preds[i][1]\n",
      "100%|██████████| 50000/50000 [00:08<00:00, 6173.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.480067</td>\n",
       "      <td>0.523808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.473331</td>\n",
       "      <td>0.531042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.477658</td>\n",
       "      <td>0.521832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.507953</td>\n",
       "      <td>0.489889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.486331</td>\n",
       "      <td>0.517263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      fake      real\n",
       "0  TEST_00000  0.480067  0.523808\n",
       "1  TEST_00001  0.473331  0.531042\n",
       "2  TEST_00002  0.477658  0.521832\n",
       "3  TEST_00003  0.507953  0.489889\n",
       "4  TEST_00004  0.486331  0.517263"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('/home/work/joono/joono/dataset/sample_submission.csv')\n",
    "\n",
    "max_thres = 0.7\n",
    "min_thres = 0.3\n",
    "\n",
    "for i in tqdm(range(len(preds))):\n",
    "    if      preds[i][0] > max_thres : submit.iloc[i, 1] = 1\n",
    "    elif    preds[i][0] < min_thres : submit.iloc[i, 1] = 0 \n",
    "    else                            : submit.iloc[i, 1] = preds[i][0]\n",
    "    if      preds[i][1] > max_thres : submit.iloc[i, 2] = 1\n",
    "    elif    preds[i][1] < min_thres : submit.iloc[i, 2] = 0 \n",
    "    else                            : submit.iloc[i, 2] = preds[i][1]\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('joono_hubert_bce_test_submit_zero_one5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(submit['fake'] < 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
