{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import HubertForSequenceClassification, AutoConfig, Wav2Vec2FeatureExtractor\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import EModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'facebook/hubert-large-ll60k'\n",
    "config = AutoConfig.from_pretrained(model_name_or_path, num_labels=2)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EModel(config=config)\n",
    "model = EModel.load_from_checkpoint(\"/home/work/joono/joono/joono/DV_DV.Deep/czvypyil/checkpoints/best-checkpoint.ckpt\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path):\n",
    "    audio, _ = librosa.load(path, sr=sampling_rate)\n",
    "    inputs = feature_extractor(audio, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    return inputs.input_values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate 함수 정의\n",
    "def collate_fn(batch):\n",
    "    signals, labels = zip(*batch)\n",
    "    max_length = max([signal.size(0) for signal in signals])\n",
    "    padded_signals = torch.zeros(len(signals), max_length)\n",
    "    for i, signal in enumerate(signals):\n",
    "        padded_signals[i, :signal.size(0)] = signal\n",
    "    labels = torch.tensor(labels)\n",
    "    return padded_signals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(\"..\", \"dataset\", self.df.loc[idx, 'path'])\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {path}\")     \n",
    "        signal = speech_file_to_array_fn(path)           \n",
    "        return signal, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../dataset/train.csv', index_col=None)\n",
    "test_df['path'] = '../dataset/' + test_df['path'].str[1:]\n",
    "test_dataset = TestDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, num_workers=24, batch_size=8, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probs = model(inputs)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(model=model, test_loader=test_loader,device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/home/work/joono/joono/dataset/train_sample_submission.csv')\n",
    "\n",
    "max_thres = 0.7\n",
    "min_thres = 0.3\n",
    "\n",
    "for i in tqdm(range(len(preds))):\n",
    "    if      preds[i][0] > max_thres : submit.iloc[i, 1] = 1\n",
    "    elif    preds[i][0] < min_thres : submit.iloc[i, 1] = 0 \n",
    "    else                            : submit.iloc[i, 1] = preds[i][0]\n",
    "    if      preds[i][1] > max_thres : submit.iloc[i, 2] = 1\n",
    "    elif    preds[i][1] < min_thres : submit.iloc[i, 2] = 0 \n",
    "    else                            : submit.iloc[i, 2] = preds[i][1]\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('joono_hubert_bce_train_submit_zero_one5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
