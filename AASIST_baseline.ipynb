{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification \n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.models import EModel, AASIST, Wav2Vec2Facebook\n",
    "from src.datamodules import AASIST2DataModule, AASISTCenterLossDataset\n",
    "from src.AASIST import AASISTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AASIST_weight_path = \"/home/work/joono/joono/joono/src/AASIST_weight/AASIST.pth\"\n",
    "classifier = AASISTModule()\n",
    "classifier.load_state_dict(torch.load(AASIST_weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate 함수 정의\n",
    "def collate_fn(batch):\n",
    "    # signals = zip(*batch)\n",
    "    signals = batch\n",
    "    max_length = max([signal.size(0) for signal in signals])\n",
    "    padded_signals = torch.zeros(len(signals), max_length)\n",
    "    for i, signal in enumerate(signals):\n",
    "        padded_signals[i, :signal.size(0)] = signal\n",
    "    # labels = torch.tensor(labels)\n",
    "    return padded_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../dataset/train.csv', index_col=None)\n",
    "test_df['path'] = '../dataset/' + test_df['path'].str[1:]\n",
    "# test_dataset = TestDataset(test_df)\n",
    "test_dataset = AASISTCenterLossDataset(test_df, train_mode=False)\n",
    "# test_loader = DataLoader(test_dataset, shuffle=False, num_workers=24, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, num_workers=24, batch_size=128, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        # for inputs, labels in tqdm(test_loader):\n",
    "        for inputs in tqdm(test_loader):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            \n",
    "            logit, _ = model(inputs)\n",
    "            probs = torch.sigmoid(logit)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [01:20<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model=classifier, test_loader=test_loader, device='cuda:0')\n",
    "# preds = model.inference(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55438 [00:00<?, ?it/s]/tmp/ipykernel_2127198/3636171141.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6289139986038208' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  submit.iloc[i, 1] = preds[i][fake]\n",
      "/tmp/ipykernel_2127198/3636171141.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7821370363235474' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  submit.iloc[i, 2] = preds[i][real]\n",
      "100%|██████████| 55438/55438 [00:08<00:00, 6170.92it/s]\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('/home/work/joono/joono/dataset/train_sample_submission.csv')\n",
    "\n",
    "max_thres = 0.999999\n",
    "min_thres = 0.000001\n",
    "\n",
    "fake, real = 1, 0\n",
    "\n",
    "for i in tqdm(range(len(preds))):\n",
    "    submit.iloc[i, 1] = preds[i][fake]\n",
    "    submit.iloc[i, 2] = preds[i][real]\n",
    "    \n",
    "    # if      preds[i][0] > max_thres : submit.iloc[i, 1] = 1\n",
    "    # elif    preds[i][0] < min_thres : submit.iloc[i, 1] = 0 \n",
    "    # else                            : submit.iloc[i, 1] = preds[i][0]\n",
    "    # if      preds[i][1] > max_thres : submit.iloc[i, 2] = 1\n",
    "    # elif    preds[i][1] < min_thres : submit.iloc[i, 2] = 0 \n",
    "    # else                            : submit.iloc[i, 2] = preds[i][1]\n",
    "    # if      preds[i][fake] > max_thres  : submit.iloc[i, 1] = 1\n",
    "    # elif    preds[i][fake] < min_thres  : submit.iloc[i, 1] = 0 \n",
    "    # else                                : submit.iloc[i, 1] = preds[i][0]\n",
    "    # if      preds[i][real] > max_thres  : submit.iloc[i, 2] = 1\n",
    "    # elif    preds[i][real] < min_thres  : submit.iloc[i, 2] = 0 \n",
    "    # else                                : submit.iloc[i, 2] = preds[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('AASIST_train_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids, paths = [], []\n",
    "for ul_path in glob(\"/home/work/joono/joono/dataset/unlabeled_data/*\"):\n",
    "    basename = os.path.basename(ul_path)\n",
    "    id = basename.split(\".\")[0]\n",
    "    path = os.path.join(\".\", \"unlabeled_data\", basename)\n",
    "    \n",
    "    ids.append(id)\n",
    "    paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"id\": ids,\n",
    "    \"path\": paths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"unlabled_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[763]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
